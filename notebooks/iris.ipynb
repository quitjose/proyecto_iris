{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar datos del DataSet IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <td>5.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0            1            2            3            4\n",
       "Id                       1            2            3            4            5\n",
       "SepalLengthCm          5.1          4.9          4.7          4.6          5.0\n",
       "SepalWidthCm           3.5          3.0          3.2          3.1          3.6\n",
       "PetalLengthCm          1.4          1.4          1.3          1.5          1.4\n",
       "PetalWidthCm           0.2          0.2          0.2          0.2          0.2\n",
       "Species        Iris-setosa  Iris-setosa  Iris-setosa  Iris-setosa  Iris-setosa"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../datasets/iris_dataset.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las columas necesarias para el estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['PetalLengthCm', 'PetalWidthCm']\n",
    "X = df[columnas].values\n",
    "y = df['Species'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el conjunto de entrenamiento (70%) y prueba (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 70%\n",
      "X_test: 30%\n",
      "y_train: 70%\n",
      "y_test: 30%\n"
     ]
    }
   ],
   "source": [
    "#entrenamos los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify = y)\n",
    "\n",
    "print(\"X_train: \"+str(int(len((X_train))/150*100))+\"%\")\n",
    "print(\"X_test: \"+str(int(len((X_test))/150*100))+\"%\")\n",
    "print(\"y_train: \"+str(int(len((y_train))/150*100))+\"%\")\n",
    "print(\"y_test: \"+str(int(len((y_test))/150*100))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4 0.2]\n",
      " [1.7 0.2]\n",
      " [5.3 2.3]\n",
      " [5.7 2.1]\n",
      " [1.2 0.2]\n",
      " [5.6 2.4]\n",
      " [6.6 2.1]\n",
      " [1.2 0.2]\n",
      " [5.8 1.6]\n",
      " [4.6 1.3]]\n",
      "[[-1.33269725 -1.30380366]\n",
      " [-1.16537974 -1.30380366]\n",
      " [ 0.84243039  1.44465434]\n",
      " [ 1.0655204   1.18289644]\n",
      " [-1.44424226 -1.30380366]\n",
      " [ 1.0097479   1.57553329]\n",
      " [ 1.56747294  1.18289644]\n",
      " [-1.44424226 -1.30380366]\n",
      " [ 1.12129291  0.52850167]\n",
      " [ 0.45202286  0.13586482]]\n",
      "[[5.4 2.3]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [4.5 1.7]\n",
      " [4.4 1.4]\n",
      " [4.  1.3]\n",
      " [5.8 1.8]\n",
      " [4.5 1.5]\n",
      " [5.3 1.9]\n",
      " [1.3 0.4]]\n",
      "[[ 0.89820289  1.44465434]\n",
      " [-1.16537974 -1.04204575]\n",
      " [-1.33269725 -1.17292471]\n",
      " [ 0.39625036  0.65938063]\n",
      " [ 0.34047786  0.26674377]\n",
      " [ 0.11738784  0.13586482]\n",
      " [ 1.12129291  0.79025958]\n",
      " [ 0.39625036  0.39762272]\n",
      " [ 0.84243039  0.92113853]\n",
      " [-1.38846976 -1.04204575]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "#mostramos la relación entre los datos y su escalado estandar\n",
    "print(X_train[0:10])\n",
    "print(X_train_std[0:10])\n",
    "print(X_test[0:10])\n",
    "print(X_test_std[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y predicción para el modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98% de las predicciones correctas en el conjunto de pruebas del modelo de Regresión Logística\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "regresion_model = LogisticRegression(random_state = 1)\n",
    "regresion_model = regresion_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regresion_model.predict(X_test)\n",
    "print (str(int(round((y_test == y_pred).mean(), 2)*100))+\"% de las predicciones correctas en el conjunto de pruebas del modelo de Regresión Logística\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y predicción para el modelo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98% de las predicciones correctas en el conjunto de pruebas del modelo SVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear',C=1.0,random_state=1, probability=True)\n",
    "svm_model = svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print (str(int(round((y_test == y_pred).mean(), 2)*100))+\"% de las predicciones correctas en el conjunto de pruebas del modelo SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y predicción para el modelo de árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98% de las predicciones correctas en el conjunto de pruebas del modelo de árbol de decisión\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion=\"gini\", max_depth=4,random_state=1)\n",
    "tree_model = tree_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = tree_model.predict(X_test)\n",
    "print (str(int(round((y_test == y_pred).mean(), 2)*100))+\"% de las predicciones correctas en el conjunto de pruebas del modelo de árbol de decisión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y predicción para el modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98% de las predicciones correctas en el conjunto de pruebas del modelo KNN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, p=2, metric='minkowski')\n",
    "knn_model = knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test)\n",
    "print (str(int(round((y_test == y_pred).mean(), 2)*100))+\"% de las predicciones correctas en el conjunto de pruebas del modelo KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos la serialización de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/iris-regresion_model.pck', 'wb') as f:\n",
    "    pickle.dump(regresion_model, f)\n",
    "\n",
    "with open('../models/iris-svm_model.pck', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n",
    "with open('../models/iris-tree_model.pck', 'wb') as f:\n",
    "    pickle.dump(tree_model, f)\n",
    "\n",
    "with open('../models/iris-knn_model.pck', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
